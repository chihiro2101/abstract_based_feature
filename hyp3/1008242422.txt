the simplest primality test is trial division : given an input number , n , check whether it is evenly divisible by any prime number between 2 and ( i.e riesel ( 1994 ) pp.2-3 for example , consider the number 100 , which is evenly divisible by these numbers : :2 , 4 , 5 , 10 , 20 , 25 , 50 note that the largest factor , 50 , is half of 100 to observe this , rewrite the list of divisors as a list of products , each equal to 100 : :2 × 50 , & nbsp ; & nbsp ; 4 × 25 , & nbsp ; & nbsp ; 5 × 20 , & nbsp ; & nbsp ; 10 × 10 , & nbsp ; & nbsp ; 20 × 5 , & nbsp ; & nbsp ; 25 × 4 , & nbsp ; & nbsp ; 50 × 2 notice that products past 10 x 10 merely repeat numbers which appeared in earlier products a combination of shor 's algorithm , an integer factorization method , with the pocklington primality test could solve the problem in o ( ( \log n ) ^3 ( \log\log n ) ^2 \log\log\log n ) however , as this test requires a partial factorization of n & nbsp ; − & nbsp ; 1 the running time was still quite slow in the worst case the first deterministic primality test significantly faster than the naive methods was the cyclotomy test ; its runtime can be proven to be o ( ( log & nbsp ; n ) c & nbsp ; log & nbsp ; log & nbsp ; log & nbsp ; n ) , where n is the number to test for primality and c is a constant independent of n ( note that running time is measured in terms of the size of the input , which in this case is ~ log & nbsp ; n , that being the number of bits needed to represent the number n ) the elliptic curve primality test can be proven to run in o ( ( log & nbsp ; n ) 6 ) , if some conjectures on analytic number theory are true similarly , under the generalized riemann hypothesis , the deterministic miller 's test , which forms the basis of the probabilistic miller–rabin test , can be proved to run in õ ( ( log & nbsp ; n ) 4 ) in practice , this algorithm is slower than the other two for sizes of numbers that can be dealt with at all 