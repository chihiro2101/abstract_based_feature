the rete algorithm provides the basis for a more efficient implementation each node has a memory of facts which satisfy that pattern as new facts are asserted or modified , they propagate along the network , causing nodes to be annotated when that fact matches that pattern rete was first used as the core engine of the ops5 production system language which was used to build early systems including r1 for digital equipment corporation '' rete algorithm demystified ! – part 1 '' by carole-ann matignon the rete algorithm is designed to sacrifice memory for increased speed in most cases , the speed increase over naïve implementations is several orders of magnitude ( because rete performance is theoretically independent of the number of rules in the system ) in very large expert systems , however , the original rete algorithm tends to run into memory and server consumption problems the rete algorithm provides a generalized logical description of an implementation of functionality responsible for matching data tuples ( '' facts '' ) against productions ( '' rules '' ) in a pattern-matching production system ( a category of rule engine ) a production consists of one or more conditions and a set of actions which may be undertaken for each complete set of facts that match the conditions conditions test fact attributes , including fact type specifiers/identifiers it allows for efficient removal of memory elements when facts are retracted from working memory when facts are '' asserted '' to working memory , the engine creates working memory elements ( wmes ) for each fact facts are n-tuples , and may therefore contain an arbitrary number of data items each wme may hold an entire n-tuple , or , alternatively , each fact may be represented by a set of wmes where each wme contains a fixed-length tuple in this case , tuples are typically triplets ( 3-tuples ) each wme enters the rete network at a single root node the root node passes each wme on to its child nodes , and each wme may then be propagated through the network , possibly being stored in intermediate memories , until it arrives at a terminal node if a wme is successfully matched against the conditions represented by one node , it is passed to the next node these memories store collections of wmes that match each condition in each node in a given node branch wmes that fail to match at least one condition in a branch are not materialised within the corresponding alpha memory as any one wme list passes through the beta network , new wmes may be added to it , and the list may be stored in beta memories a wme list in a beta memory represents a partial match for the conditions in a given production wme lists that reach the end of a branch of beta nodes represent a complete match for a single production , and are passed to terminal nodes each terminal node represents a single production , and each wme list that arrives at a terminal node represents a complete set of matching wmes for the conditions in that production for each wme list it receives , a production node will '' activate '' a new production instance on the '' agenda '' when a join node is left-activated it traverses a single newly stored wme list in the beta memory , retrieving specific attribute values of given wmes each beta node outputs wme lists which are either stored in a beta memory or sent directly to a terminal node wme lists are stored in beta memories whenever the engine will perform additional left activations on subsequent beta nodes some engines use specialised adapter nodes to connect alpha memories to the left input of beta nodes other engines allow beta nodes to take input directly from two alpha memories , treating one as a '' left '' input and the other as a '' right '' input in both cases , '' head '' beta nodes take their input from two alpha memories in order to eliminate node redundancies , any one alpha or beta memory may be used to perform activations on multiple beta nodes in this case , there may be no need to store wmes in alpha memories during any one match-resolve-act cycle , the engine will find all possible matches for the facts currently asserted to working memory once all the current matches have been found , and corresponding production instances have been activated on the agenda , the engine determines an order in which the production instances may be '' fired '' the order may be based on rule priority ( salience ) , rule order , the time at which facts contained in each instance were asserted to the working memory , the complexity of each production , or some other criteria conflict resolution is not defined as part of the rete algorithm , but is used alongside the algorithm by default , the engine will continue to fire each production instance in order until all production instances have been fired however , the sequence of production instance firings may be interrupted at any stage by performing changes to the working memory each time any single production instance performs one or more such changes , the engine immediately enters a new match-resolve-act cycle they may also provide automatic loop detection in which never-ending loops are automatically halted after a given number of iterations as for conflict resolution , the firing of activated production instances is not a feature of the rete algorithm for a more detailed and complete description of the rete algorithm , see chapter 2 of production matching for large learning systems by robert doorenbos ( see link below ) if a subsequent change to working memory causes the first match to become invalid , it may be that this implies that the second match is also invalid rete2 from production systems technologies unlike the original rete ( which is public domain ) this algorithm was not disclosed the rete iii algorithm , which is not rete-nt , is the fico trademark for rete ii and is implemented as part of the fico advisor engine 