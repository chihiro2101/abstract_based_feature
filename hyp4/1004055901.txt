each news article contains a complete set of header lines , but in common use the term '' headers '' is also used when referring to the news overview database the overview is a list of the most frequently used headers , and additional information such as article sizes , typically retrieved by the client software using the nntp xover command overviews make reading a newsgroup faster for both the client and server by eliminating the need to open each individual article to present them in list form if non-overview headers are required , such as for when using a kill file , it may still be necessary to use the slower method of reading all the complete article headers among the operators and users of commercial news servers , common concerns are the continually increasing storage and network capacity requirements and their effects completion ( the ability of a server to successfully receive all traffic ) , retention ( the amount of time articles are made available to readers ) and overall system performance speed , in relation to usenet , is how quickly a server can deliver an article to the user the server that the user connects to is typically part of a server farm that has many servers dedicated to multiple tasks some servers allow as many as 60 simultaneous connections , but this varies widely based on the provider this generally means that a server can run with less overhead which makes for a more efficient server , but gives less articles for users to access in the modern era , high speed connections , large storage capacity , and advanced search tools allows users to utilize extensive retention without any drawbacks retention is generally quoted separately for text and binary articles , though it may also vary between different groups within these categories large news providers offer text retention up to 2480 days and binary retention of 850 days or more omicron 's hw media is currently the usenet server with the highest amount of binary retention , while google is the usenet server with the highest amount of text retention one common method is to examine the oldest articles in a group and examine the date , but this is not always accurate some articles in a group may be retained for longer than others , articles from remote servers do not always arrive promptly , and at times the date headers are simply incorrect to deal with the increase of usenet traffic , many providers turn to a hybrid system , in which old articles not found on the provider 's server will request the article from another server with longer retention given the large number of articles transferred between servers and the large size of individual articles , their complete propagation to any one server farm is not guaranteed looking at only one server , one can not know how many articles were actually inserted throughout the network all usenet servers peer with one or more other servers in order to exchange articles there are several common ways in which the spool may be organized : one file per article is the oldest storage scheme , still in common use on smaller servers and replicated in many clients there is , however , less flexibility to retain articles by age rather than space used , and traditional text manipulation tools such as grep are less well suited to analyzing these files various hybrid storage schemes have also been used in news servers , including different organizations of the file-per-article method , or smaller containers carrying perhaps 100 articles apiece these perform the same reader server role as conventional news servers , but themselves act as newsreaders to exchange articles with other reader servers list of news servers 