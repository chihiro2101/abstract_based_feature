end users often use the term '' posting '' to refer to a single message or file posted to usenet each news article contains a complete set of header lines , but in common use the term '' headers '' is also used when referring to the news overview database the overview is a list of the most frequently used headers , and additional information such as article sizes , typically retrieved by the client software using the nntp xover command if non-overview headers are required , such as for when using a kill file , it may still be necessary to use the slower method of reading all the complete article headers these server farms are continually monitored by both insiders and outsiders , and measurements of these characteristics are often used by consumers when choosing a commercial news service speed , in relation to usenet , is how quickly a server can deliver an article to the user the server that the user connects to is typically part of a server farm that has many servers dedicated to multiple tasks once the farm is able to deliver the data to the network , then the provider has limited control over the speed to the user since the network path to each user is different , some users will have good routes and the data will flow quickly some servers allow as many as 60 simultaneous connections , but this varies widely based on the provider article sizes are limited to what each news server will accept the larger the article size , the more space it occupies , and thus the fewer articles on each server retention is simply defined as how long the server keeps articles as of 2009 , it is common for average news providers to have text retention of over 1000 days and binary retention of over 200 days large news providers offer text retention up to 2480 days and binary retention of 850 days or more omicron 's hw media is currently the usenet server with the highest amount of binary retention , while google is the usenet server with the highest amount of text retention some articles in a group may be retained for longer than others , articles from remote servers do not always arrive promptly , and at times the date headers are simply incorrect a sampling of many or all articles , preferably in more than one newsgroup , is required to detect such anomalies to deal with the increase of usenet traffic , many providers turn to a hybrid system , in which old articles not found on the provider 's server will request the article from another server with longer retention given the large number of articles transferred between servers and the large size of individual articles , their complete propagation to any one server farm is not guaranteed articles may never make their way outside the originating server , or may fail to find their way out to the transit cloud they are typically filed in special '' control '' newsgroups and may cause the server to automatically carry out exceptional actions a reader server typically also works as a transit server , but it may operate independently or serve as an alternative interface to an internet forum these perform the same reader server role as conventional news servers , but themselves act as newsreaders to exchange articles with other reader servers they may also be the only available means to obtain articles from remote servers that do not offer conventional feeding 