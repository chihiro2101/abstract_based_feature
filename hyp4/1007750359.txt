in the case of normal distribution data , the three sigma rule means that roughly 1 in 22 observations will differ by twice the standard deviation or more from the mean , and 1 in 370 will deviate by three times the standard deviation in a sample of 1000 observations , the presence of up to five observations deviating from the mean by more than three times the standard deviation is within the range of what can be expected , being less than twice the expected number and hence within 1 standard deviation of the expected number – see poisson distribution – and not indicate an anomaly thus if one takes a normal distribution with cutoff 3 standard deviations from the mean , p is approximately 0.3 % , and thus for 1000 trials one can approximate the number of samples whose deviation exceeds 3 sigmas by a poisson distribution with λ 3 a physical apparatus for taking measurements may have suffered a transient malfunction there may have been an error in data transmission or transcription additionally , the pathological appearance of outliers of a certain form appears in a variety of datasets , indicating that the causative mechanism for the data might differ at the extreme end ( king effect ) there is no rigid mathematical definition of what constitutes an outlier ; determining whether or not an observation is an outlier is ultimately a subjective exercise it is proposed to determine in a series of m observations the limit of error , beyond which all observations involving so great an error may be rejected , provided there are as many as n such observations the modified thompson tau test is a method used to determine if an outlier exists in a data set the strength of this method lies in the fact that it takes into account a data set 's standard deviation , average and provides a statistically determined rejection zone ; thus providing an objective method to determine if a data point is an outlier deletion of outlier data is a controversial practice frowned upon by many scientists and science instructors ; while mathematical criteria provide an objective and quantitative method for data rejection , they do not make the practice more scientifically or methodologically sound , especially in small sets or where a normal distribution can not be assumed from mathworld -- a wolfram web resource the sample variance increases with the sample size , the sample mean fails to converge as the sample size increases , and outliers are expected at far larger rates than for a normal distribution in cases where the cause of the outliers is known , it may be possible to incorporate this effect into the model structure , for example by using a hierarchical bayes model , or a mixture model 