in 1925 , ronald fisher advanced the idea of statistical hypothesis testing , which he called '' tests of significance '' , in his publication statistical methods for research workers fisher suggested a probability of one in twenty ( 0.05 ) as a convenient cutoff level to reject the null hypothesis in a 1933 paper , jerzy neyman and egon pearson called this cutoff the significance level , which they named \alpha in his 1956 publication statistical methods and scientific inference , he recommended that significance levels be set according to specific circumstances the significance level \alpha is the threshold for p below which the null hypothesis is rejected even though by assumption it were true , and something else is going on this means that \alpha is also the probability of mistakenly rejecting the null hypothesis , if the null hypothesis is true this is the probability of not rejecting the null hypothesis given that it is true statistical significance plays a pivotal role in statistical hypothesis testing for the null hypothesis to be rejected , an observed result has to be statistically significant , i.e the observed p-value is less than the pre-specified significance level \alpha to determine whether a result is statistically significant , a researcher calculates a p-value , which is the probability of observing an effect of the same magnitude or more extreme given that the null hypothesis is true the null hypothesis is rejected if the p-value is less than ( or equal to ) a predetermined level , \alpha \alpha is also called the significance level , and is the probability of rejecting the null hypothesis given that it is true ( a type i error ) as a result , the null hypothesis can be rejected with a less extreme result if a one-tailed test was used effect size is a measure of a study 's practical significance a statistically significant result may have a weak effect reviews problems with null hypothesis statistical testing 